### Install and Start Minikube:

â–¶ https://minikube.sigs.k8s.io/docs/start/

Note that, to work with spark, we need a cluster of kubernetes (k8s) with more resources than usual. So, create the Minikube cluster by the following command:

```bash
$ minikube start --memory 6144 --cpus 4

# This command make a cluster with 6GB RAM and 4 CPUs. You can change the RAM based on your resources. 

$ New-Alias -Name k -Value kubectl
# This command make an alias for kubectl simply as k
```

ðŸ›‘ If you are interested to set permanent aliases in windows see this tutorial
â–¶ https://www.m-fozouni.ir/alias-in-windows-and-linux/  

ðŸ›‘ If we have `docker-desktop` , `kubectl` command will **point to**
 `C:\Program Files\Docker\Docker\resources\bin\kubectl.exe`

ðŸ›‘ If you do not have `docker-desktop` to use of its `kubectl client`, do not worry. you can install it from here
â–¶ https://kubernetes.io/docs/tasks/tools/install-kubectl-windows/ 

### Create a three nodes cluster by Minikube:

â–¶ https://medium.com/womenintechnology/create-a-3-node-kubernetes-cluster-with-minikube-8e3dc57d6df2

### Start with more memory and CPU:

â–¶ https://www.shellhacks.com/minikube-start-with-more-memory-cpus/

### Start to work:

```bash
$ minikube docker-env
# This command will give us a session for which we can comminucate with Minikube's docker and see the docker images in it.  

$ kubectl create -f spark-master-deployment.yaml

$ kubectl create -f spark-master-service.yaml

$ minikube dashboard
```

Check your cluster:

```bash
$ kubectl get deployments

$ kubectl get pods
```

### Create one more component: 

```bash
$ kubectl create -f spark-worker-deployment.yaml

$ kubectl get deployments

$ kubectl get pods
```

### Ingress:

```bash
$ minikube addons enable ingress

$ kubectl apply -f minikube-ingress.yaml
```

### Add one DNS to your host:

```bash
$ minikube ip
# add the output to your host. For example if it is 45.78.65.45, add the following line

# 45.78.65.45 spark-kubernetes

Now, go to http://spark-kubernetes/ to see the GUI of spark. 
```

ðŸ›‘ Note: The address of my hosts file == `C:\Windows\System32\drivers\etc\hosts.` Sometimes this file changed to `read-only` and you can not insert any item in it. 

### Test you cluster:

```bash
$ kubectl get pods -o wide

NAME                            READY   STATUS    RESTARTS   AGE     IP           NODE       NOMINATED NODE   READINESS GATES
spark-master-dbc47bc9-t6v84     1/1     Running   0          7m35s   172.17.0.6   minikube   <none>           <none>
spark-worker-795dc47587-5ch8f   1/1     Running   0          7m24s   172.17.0.9   minikube   <none>           <none>
spark-worker-795dc47587-fvcf6   1/1     Running   0          7m24s   172.17.0.7   minikube   <none>           <none>

$ kubectl exec spark-master-dbc47bc9-t6v84 -it -- \
    pyspark --conf spark.driver.bindAddress=172.17.0.6 --conf spark.driver.host=172.17.0.6
```

### Now, run the following lines to see if your spark cluster works well:

```bash
$ words = 'the quick brown fox jumps over the lazy dog the quick brown fox jumps over the lazy dog and what do think will happen'
        
$ sc = SparkContext.getOrCreate()

$ seq = words.split()

$ data = sc.parallelize(seq)

$ counts = data.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b).collect()

$ dict(counts)

$ sc.stop()
```



